#BY MEDIC
import speech_recognition as sr
import pyttsx3
import webbrowser
import customtkinter as ctk
import json
import threading
import time
import os
import subprocess
import pyautogui
from ctypes import cast, POINTER
from comtypes import CLSCTX_ALL
from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume
import audioop
from threading import Lock
import pyperclip
from PIL import Image
from datetime import datetime

#loading images
imagepath_announce = os.path.join("assets", "announce.png")
image_announce = ctk.CTkImage(Image.open(imagepath_announce), size=(380, 300))

imagepath_default = os.path.join("assets", "default.png")
image_default = ctk.CTkImage(Image.open(imagepath_default), size=(250, 250))

imagepath_listen = os.path.join("assets", "listen.png")
image_listen = ctk.CTkImage(Image.open(imagepath_listen), size=(250, 250))

imagepath_happy = os.path.join("assets", "happy.png")
image_happy = ctk.CTkImage(Image.open(imagepath_happy), size=(250, 250))

mic_lock = Lock()

# gui init
engine = pyttsx3.init()
ctk.set_appearance_mode("dark")
ctk.set_default_color_theme("blue")

# json loading
with open("commands.json", "r", encoding="utf-8") as f:
    commands = json.load(f)

    paths = json.load(open("paths.json"))

    
# audio
def speak(text):
    engine.say(text)
    engine.runAndWait()

#time checking
def format_time():
    now = datetime.now()
    hours = now.hour
    minutes = now.minute

    h_form = (
        "—á–∞—Å" if hours % 10 == 1 and hours % 100 != 11 else
        "—á–∞—Å–∞" if 2 <= hours % 10 <= 4 and not 12 <= hours % 100 <= 14 else
        "—á–∞—Å–æ–≤"
    )

    m_form = (
        "–º–∏–Ω—É—Ç–∞" if minutes % 10 == 1 and minutes % 100 != 11 else
        "–º–∏–Ω—É—Ç—ã" if 2 <= minutes % 10 <= 4 and not 12 <= minutes % 100 <= 14 else
        "–º–∏–Ω—É—Ç"
    )

    return f"{hours} {h_form}, {minutes} {m_form}"


# proccesing commands
def process_command(command, listening_forever=False):
    command = command.lower()

    # emotes
    if any(phrase in command for phrase in ["–∫–∞–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ"]):
        emotion_label.configure(image=image_happy)
        speak("–£ –º–µ–Ω—è –≤—Å—ë –æ—Ç–ª–∏—á–Ω–æ, —Å–ø–∞—Å–∏–±–æ!")
        return
    for key in commands:
        if key in command:
            action = commands[key]
            if action == "open_browser":
                webbrowser.open("https://google.com")
                log("–û—Ç–∫—Ä—ã—Ç –±—Ä–∞—É–∑–µ—Ä")
                speak("–û—Ç–∫—Ä—ã–≤–∞—é –±—Ä–∞—É–∑–µ—Ä")
            elif action == "open_youtube":
                webbrowser.open("https://youtube.com")
                log("–û—Ç–∫—Ä—ã—Ç YouTube")
                speak("–û—Ç–∫—Ä—ã–≤–∞—é —é—Ç—É–±")
            elif action == "open_vk":
                webbrowser.open("https://vk.com")
                log("–û—Ç–∫—Ä—ã—Ç –í–ö–æ–Ω—Ç–∞–∫—Ç–µ")
                speak("–û—Ç–∫—Ä—ã–≤–∞—é –í–ö–æ–Ω—Ç–∞–∫—Ç–µ")
            elif action == "open_steam":
                subprocess.Popen(paths["steam"])
                log("–û—Ç–∫—Ä—ã—Ç Steam")
                speak("–û—Ç–∫—Ä—ã–≤–∞—é —Å—Ç–∏–º")
            elif action == "open_discord":
                subprocess.Popen([paths["discord"], "--processStart", "Discord.exe"])
                log("–û—Ç–∫—Ä—ã—Ç Discord")
                speak("–û—Ç–∫—Ä—ã–≤–∞—é –¥–∏—Å–∫–æ—Ä–¥")
            elif action == "shutdown":
                speak("–í—ã–∫–ª—é—á–∞—é –∫–æ–º–ø—å—é—Ç–µ—Ä")
                os.system("shutdown /s /t 5")
            elif action == "restart":
                speak("–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞—é –∫–æ–º–ø—å—é—Ç–µ—Ä")
                os.system("shutdown /r /t 5")
            elif action == "open_cmd":
                subprocess.Popen("cmd.exe")
                log("–û—Ç–∫—Ä—ã—Ç –∫–æ–º–∞–Ω–¥–Ω—ã–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä")
                speak("–û—Ç–∫—Ä—ã–≤–∞—é –∫–æ–º–∞–Ω–¥–Ω—É—é —Å—Ç—Ä–æ–∫—É")
            elif action == "open_folder":
                os.startfile("C:\\")
                log("–û—Ç–∫—Ä—ã—Ç –¥–∏—Å–∫ C")
                speak("–û—Ç–∫—Ä—ã–≤–∞—é –¥–∏—Å–∫ C")
            elif action == "volume_up":
                set_volume(10)
                speak("–ì—Ä–æ–º–∫–æ—Å—Ç—å —É–≤–µ–ª–∏—á–µ–Ω–∞")
            elif action == "volume_down":
                set_volume(-10)
                speak("–ì—Ä–æ–º–∫–æ—Å—Ç—å —É–º–µ–Ω—å—à–µ–Ω–∞")
            elif action == "pause_play":
                pyautogui.press("playpause")
                speak("–ü–∞—É–∑–∞")
            elif action == "minimize_window":
                pyautogui.hotkey("win", "down")
                speak("–û–∫–Ω–æ —Å–≤–µ—Ä–Ω—É—Ç–æ")
            elif action == "fullscreen":
                pyautogui.press("f")
                speak("–ü–æ–ª–Ω–æ—ç–∫—Ä–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º")
            elif action == "windowed":
                pyautogui.press("f11")
                speak("–û–∫–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º")
            elif action == "open_roblox":
                webbrowser.open("https://www.roblox.com/home")
                log("–û—Ç–∫—Ä—ã—Ç –†–æ–±–ª–æ–∫—Å")
                speak("–†–æ–±–ª–æ–∫—Å –æ—Ç–∫—Ä—ã—Ç")
            elif action == "open_gpt":
                webbrowser.open("https://chatgpt.com")
                log("–û—Ç–∫—Ä—ã—Ç –ß–∞—Ç–ì–ü–¢")
                speak("–ß–∞—Ç–ì–ü–¢ –æ—Ç–∫—Ä—ã—Ç")
            elif action == "close_tab":
                pyautogui.hotkey("ctrl", "w")
                log("–í–∫–ª–∞–¥–∫–∞ –∑–∞–∫—Ä—ã—Ç–∞")
                speak("–ó–∞–∫—Ä—ã–ª–∞ –≤–∫–ª–∞–¥–∫—É")
            elif action == "open_mail":
                webbrowser.open("https://mail.ru")
                log("–û—Ç–∫—Ä—ã—Ç–∞ –ø–æ—á—Ç–∞")
                speak("–ü–æ—á—Ç–∞ –æ—Ç–∫—Ä—ã—Ç–∞")
            elif action == "search":
                search_query = command.replace("–ø–æ–∏—Å–∫", "", 1).replace("–Ω–∞–π–¥–∏", "", 1).replace("–ø–æ–∏—â–∏", "", 1).strip()
                if search_query:
                    webbrowser.open(f"https://www.google.com/search?q={search_query}")
                    log(f"–ü–æ–∏—Å–∫: {search_query}")
                    speak(f"–ò—â—É {search_query}")
                else:
                    speak("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ, —á—Ç–æ –∏—Å–∫–∞—Ç—å.")              
            elif action == "close_window":
                pyautogui.hotkey('alt', 'f4')
                speak("–ó–∞–∫—Ä—ã–ª–∞ –æ–∫–Ω–æ")
            elif action == "click":
                pyautogui.click()
            elif action == "next":
                pyautogui.press("nexttrack")
                log("–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–æ")
                speak("–ü–µ—Ä–µ–∫–ª—é—á–∏–ª–∞")
            elif action == "open_telegram":
                subprocess.Popen([paths["telegram"]])
                log("–û—Ç–∫—Ä—ã—Ç –¢–µ–ª–µ–≥—Ä–∞–º")
                speak("–û—Ç–∫—Ä—ã–≤–∞—é –¢–µ–ª–µ–≥—Ä–∞–º")
# —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º—ã—à–∫–æ–π
            elif action == "mouse_up":
                pyautogui.move(0, -100, duration=0.5)
                log("–ö—É—Ä—Å–æ—Ä –ø–µ—Ä–µ–¥–≤–∏–Ω—É—Ç –≤–≤–µ—Ä—Ö")
            elif action == "mouse_down":
                pyautogui.move(0, 100, duration=0.5)
                log("–ö—É—Ä—Å–æ—Ä –ø–µ—Ä–µ–¥–≤–∏–Ω—É—Ç –≤–Ω–∏–∑")
            elif action == "mouse_right":
                pyautogui.move(100, 0, duration=0.5)
                log("–ö—É—Ä—Å–æ—Ä –ø–µ—Ä–µ–¥–≤–∏–Ω—É—Ç –≤–ø—Ä–∞–≤–æ")
            elif action == "mouse_left":
                pyautogui.move(-100, 0, duration=0.5)
                log("–ö—É—Ä—Å–æ—Ä –ø–µ—Ä–µ–¥–≤–∏–Ω—É—Ç –≤–ª–µ–≤–æ")
# –∫–æ–Ω–µ—Ü —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º—ã—à–∫–æ–π (—à–æ–± –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å—Å—è)
            elif action == "type":
                text_to_type = command.replace("–Ω–∞–ø–∏—à–∏", "").replace("–ø–∏—à–∏", "").replace("–Ω–∞–ø–∏—à–∏", "").strip()
                if text_to_type:
                 pyperclip.copy(text_to_type)
                pyautogui.hotkey('ctrl', 'v')
                pyperclip.paste()
                speak("–ì–æ—Ç–æ–≤–æ")
            elif action == "enter":
                pyautogui.press("enter")
                log("Enter –Ω–∞–∂–∞—Ç")      
                speak("–ü–æ—Ç–≤–µ—Ä–¥–∏–ª–∞")      
            elif action == "next_tab":
                pyautogui.hotkey("ctrl","tab")
                log("–í–∫–ª–∞–¥–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∞")
                speak("–ü–µ—Ä–µ–∫–ª—é—á–∏–ª–∞")    
            elif action == "open_music":
                webbrowser.open("https://vk.com/audios811352879")
                log("–ú—É–∑—ã–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∞")
                speak("–û—Ç–∫—Ä—ã–ª–∞ –º—É–∑—ã–∫—É")          
            elif action == "open_github":
                webbrowser.open("https://github.com/trending")
                log("–ì–∏—Ç—Ö–∞–± –æ—Ç–∫—Ä—ã—Ç")
                speak("–û—Ç–∫—Ä—ã–≤–∞—é –ì–∏—Ç—Ö–∞–±")         
            elif action == "timecheck":
                log(format_time())
                speak(format_time())            
            else:
                log(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ: {action}")
            return
    if not listening_forever:
        log("–ö–æ–º–∞–Ω–¥–∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞")
        speak("–ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞")

# audio holder
def set_volume(change):
    devices = AudioUtilities.GetSpeakers()
    interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
    volume = cast(interface, POINTER(IAudioEndpointVolume))
    current = volume.GetMasterVolumeLevelScalar()
    new_volume = min(1.0, max(0.0, current + (change / 100)))
    volume.SetMasterVolumeLevelScalar(new_volume, None)

# recognize speech
recognizer = sr.Recognizer()
selected_mic_index = None  

# getting microphones 
def get_microphone_list():
    raw_names = sr.Microphone.list_microphone_names()
    fixed_names = []
    for name in raw_names:
        try:
            fixed = name.encode('latin1').decode('utf-8')
            fixed_names.append(fixed)
        except:
            fixed_names.append(name)
    return fixed_names

# voice indicatod (WON'T WORK)
def update_voice_meter():
    while True:
        try:
            with mic_lock:
                with sr.Microphone(device_index=selected_mic_index) as source:
                    recognizer.adjust_for_ambient_noise(source, duration=0.2)
                    while True:
                        try:
                            audio = recognizer.listen(source, timeout=0.3, phrase_time_limit=0.1)
                            audio_data = audio.get_raw_data()

                            rms = audioop.rms(audio_data, 2)  
                            level = min(100, rms / 32767 * 200)  

                            app.after(0, lambda: voice_meter.set(level/100))
                        except sr.WaitTimeoutError:
                            app.after(0, lambda: voice_meter.set(0))
                        time.sleep(0.05)
        except OSError as e:
            app.after(0, lambda: log(f"–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É: {str(e)}"))
            time.sleep(2)
        except Exception as e:
            app.after(0, lambda: log(f"–û—à–∏–±–∫–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞: {str(e)}"))
            break
listen_forever = False

# listen func
def listen():
    emotion_label.configure(image=image_listen)
    log("–°–ª—É—à–∞—é...")
    try:
        with sr.Microphone(device_index=selected_mic_index) as source:
            recognizer.adjust_for_ambient_noise(source)
            while listen_forever:
                audio = recognizer.listen(source, timeout=None)  
                query = recognizer.recognize_google(audio, language="ru-RU")
                log(f"–í—ã —Å–∫–∞–∑–∞–ª–∏: {query}")
                process_command(query, listening_forever=True)
                time.sleep(0.5)
    except sr.UnknownValueError:
        pass 
    except sr.RequestError:
        log("–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ —Å–µ—Ä–≤–∏—Å—É —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è")
        speak("–ü—Ä–æ–±–ª–µ–º–∞ —Å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–æ–º")
    except Exception as e:
        log(f"–û—à–∏–±–∫–∞: {e}")
        speak("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞")
    finally:
        emotion_label.configure(image=image_default)

# listening forever

def toggle_listen_forever():
    global listen_forever
    listen_forever = not listen_forever
    if listen_forever:
        listen_forever_button.configure(text="–°–ª—É—à–∞—Ç—å –≤—Å–µ–≥–¥–∞: –í–∫–ª—é—á–µ–Ω–æ")
        threading.Thread(target=start_listening_forever, daemon=True).start()
    else:
        listen_forever_button.configure(text="–°–ª—É—à–∞—Ç—å –≤—Å–µ–≥–¥–∞: –í—ã–∫–ª—é—á–µ–Ω–æ")

def start_listening_forever():
    while listen_forever:
        listen()

# main gui
app = ctk.CTk()
app.title("Monica : PC Assistant")
app.geometry("500x780")

#emotion_label = ctk.CTkLabel(app, text=":|", font=("Arial", 40)) #old emotions
#emotion_label.pack(pady=5)

emotion_label = ctk.CTkLabel(app, image=image_default, text="")
emotion_label.pack(pady=1)

# popup show
popup = ctk.CTkToplevel()
popup.title("–í–Ω–∏–º–∞–Ω–∏–µ")
popup.geometry("480x400")
ctk.CTkLabel(popup, image=image_announce, text="").pack(pady=10)
ctk.CTkLabel(popup, text="–ü–æ–º–Ω–∏—Ç–µ! —ç—Ç–æ –æ—á–µ–Ω—å —Ä–∞–Ω–Ω–∏–π –¥–æ—Å—Ç—É–ø –∏ –≤—Å–µ –º–æ–∂–µ—Ç –ø–æ–º–µ–Ω—è—Ç—å—Å—è!", font=("Arial", 14)).pack(pady=5)
ctk.CTkLabel(popup, text="V0.13", font=("Arial", 18)).pack(pady=6)
ctk.CTkButton(popup, text="–û–ö", command=popup.destroy).pack(pady=10)

logbox = ctk.CTkTextbox(app, width=480, height=300)
logbox.pack(pady=10)
#üêü
mic_names = get_microphone_list()
microphone_menu = ctk.CTkOptionMenu(app, values=["–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é"] + mic_names, command=lambda name: set_microphone(name))
microphone_menu.set("–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é")
microphone_menu.pack(pady=10)

listen_button = ctk.CTkButton(app, text="üéô –°–ª—É—à–∞—Ç—å –∫–æ–º–∞–Ω–¥—É", command=lambda: threading.Thread(target=listen).start())
listen_button.pack(pady=10)

listen_forever_button = ctk.CTkButton(app, text="–°–ª—É—à–∞—Ç—å –≤—Å–µ–≥–¥–∞: –í—ã–∫–ª—é—á–µ–Ω–æ", command=toggle_listen_forever)
listen_forever_button.pack(pady=10)

voice_meter = ctk.CTkProgressBar(app, width=400)
voice_meter.set(0)
voice_meter.pack(pady=10)

def set_microphone(name):
    global selected_mic_index
    if name == "–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é":
        selected_mic_index = None
        log("–í—ã–±—Ä–∞–Ω –º–∏–∫—Ä–æ—Ñ–æ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –û–°")
    else:
        try:
            selected_mic_index = mic_names.index(name)
            log(f"–í—ã–±—Ä–∞–Ω –º–∏–∫—Ä–æ—Ñ–æ–Ω: {name}")
        except ValueError:
            log("–û—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞")

def log(text):
    logbox.insert("end", text + "\n")
    logbox.see("end")
    print(text)

speak("–ö –≤–∞—à–∏–º —É—Å–ª—É–≥–∞–º!")
log("–ú–æ–Ω–∏–∫–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ")
log("–í—ã–±–µ—Ä–∏—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω –∏–∑ —Å–ø–∏—Å–∫–∞ –≤—ã—à–µ –∏–ª–∏ –æ—Å—Ç–∞–≤—å—Ç–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")

threading.Thread(target=update_voice_meter, daemon=True).start()

app.mainloop()
